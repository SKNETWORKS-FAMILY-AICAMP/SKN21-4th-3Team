# ë°ì´í„° ì „ì²˜ë¦¬ ë°©ë²•ë¡  (Preprocessing Methodology)

## ê°œìš”

ì›ë³¸ ìƒë‹´ ë°ì´í„°(txt/json)ë¥¼ RAG ì‹œìŠ¤í…œì— ì í•©í•œ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ“Š ì²˜ë¦¬ í†µê³„

| í•­ëª©           | ê°’        |
| -------------- | --------- |
| ì›ë³¸ íŒŒì¼ ìˆ˜   | 2,650ê°œ   |
| ì •ë ¬ ì™„ë£Œ ì„¸ì…˜ | 1,310ê°œ   |
| ìƒì„±ëœ ë¬¸ì„œ ìˆ˜ | 129,267ê°œ |
| í‰ê·  ë¬¸ì„œ ê¸¸ì´ | 104.6ì   |

---

## ğŸ”„ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```
ì›ë³¸ í…ìŠ¤íŠ¸ (data/raw/)
    â†“ STEP 1. íŒŒì¼ ì½ê¸°
í…ìŠ¤íŠ¸ íŒŒì‹±
    â†“ STEP 2. í™”ì ì •ê·œí™”
ì²­í¬ ë¶„ë¦¬ (ìƒë‹´ì‚¬/ë‚´ë‹´ì)
    â†“ STEP 3. ìœˆë„ìš° ì²­í‚¹
ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
    â†“ STEP 4. ë ˆì´ë¸” ê²€ì¦
ìµœì¢… ë¬¸ì„œ (docs_for_vectordb.jsonl)
```

---

## ğŸ¯ í•µì‹¬ ì„¤ê³„ ê²°ì •

### 1. í™”ì ì •ê·œí™” (Speaker Normalization)

**ë¬¸ì œ:** ì›ë³¸ ë°ì´í„°ì—ì„œ í™”ì í‘œê¸°ê°€ ì¼ê´€ë˜ì§€ ì•ŠìŒ

- "T", "ìƒë‹´ì", "ìƒë‹´ê°€", "ì¹˜ë£Œì" â†’ ëª¨ë‘ ë‹¤ë¥¸ í‘œê¸°

**í•´ê²°:** `norm()` í•¨ìˆ˜ë¡œ í†µì¼

```python
# ë³€í™˜ ê·œì¹™
"T" â†’ "ìƒë‹´ì‚¬"
"C" â†’ "ë‚´ë‹´ì"
"ìƒë‹´ì", "ìƒë‹´ê°€", "ì¹˜ë£Œì" â†’ "ìƒë‹´ì‚¬"
"ê³ ê°", "ì‚¬ìš©ì" â†’ "ë‚´ë‹´ì"
```

**ì´ìœ :** ì¼ê´€ëœ í™”ì í‘œê¸°ë¥¼ í†µí•´ ë©”íƒ€ë°ì´í„° í•„í„°ë§ ë° RAG ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ

---

### 2. ìœˆë„ìš° ì²­í‚¹ (Window Chunking)

**ë¬¸ì œ:** ë‹¨ì¼ ë°œí™”ë§Œ ì„ë² ë”©í•˜ë©´ ë¬¸ë§¥ì´ ì†ì‹¤ë¨

**í•´ê²°:** ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ (i-1, i, i+1)

```python
def build_window_text(chunks, i: int, window: int = 1):
    # ì´ì „ ë°œí™” + í˜„ì¬ ë°œí™” + ë‹¤ìŒ ë°œí™” ê²°í•©
    start = max(0, i - window)
    end = min(len(chunks) - 1, i + window)
    # ...
```

**ì˜ˆì‹œ:**

```
[i-1] ìƒë‹´ì‚¬: ìš”ì¦˜ ì–´ë– ì„¸ìš”?
[i]   ë‚´ë‹´ì: ë„ˆë¬´ í˜ë“¤ì–´ìš”        â† ì¤‘ì‹¬ ë°œí™”
[i+1] ìƒë‹´ì‚¬: êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì ì´ í˜ë“œì‹ ê°€ìš”?
```

**ì´ìœ :**

- **ë¬¸ë§¥ ë³´ì¡´**: ì§ˆë¬¸-ë‹µë³€ ìŒì´ í•¨ê»˜ ì„ë² ë”©ë˜ì–´ ì˜ë¯¸ì  ì—°ê´€ì„± ìœ ì§€
- **ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ**: "í˜ë“¤ì–´ìš”"ë§Œìœ¼ë¡œ ê²€ìƒ‰í•´ë„ ì ì ˆí•œ ìƒë‹´ì‚¬ ì‘ë‹µ í¬í•¨
- **ìµœì†Œ ë‹¨ìœ„ ìœ ì§€**: window=1ë¡œ ì„¤ì •í•˜ì—¬ ê³¼ë„í•œ ì»¨í…ìŠ¤íŠ¸ í™•ì¥ ë°©ì§€

---

### 3. ìƒë‹´ì‚¬ ì‘ë‹µ ë©”íƒ€ë°ì´í„°

**ë¬¸ì œ:** ë‚´ë‹´ì ì§ˆë¬¸ì— ëŒ€í•œ ì „ë¬¸ê°€ ë‹µë³€ì´ ì„ë² ë”©ì—ëŠ” í¬í•¨ë˜ì§€ë§Œ ëª…í™•íˆ ë¶„ë¦¬ë˜ì§€ ì•ŠìŒ

**í•´ê²°:** `get_next_counselor_response()` í•¨ìˆ˜ë¡œ ë‹¤ìŒ ìƒë‹´ì‚¬ ì‘ë‹µì„ ë³„ë„ ë©”íƒ€ë°ì´í„°ë¡œ ì €ì¥

```python
def get_next_counselor_response(chunks, i: int) -> str:
    for j in range(i + 1, len(chunks)):
        if chunks[j].get("speaker") == "ìƒë‹´ì‚¬":
            return normalize_text(chunks[j].get("utterance", ""))
    return ""
```

**ì´ìœ :** LLMì´ ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ **ì „ë¬¸ ìƒë‹´ì‚¬ì˜ ì‹¤ì œ ë‹µë³€**ì„ ì°¸ì¡°í•  ìˆ˜ ìˆë„ë¡ ë©”íƒ€ë°ì´í„°ì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨

---

### 4. í…ìŠ¤íŠ¸ ì •ê·œí™”

**ì²˜ë¦¬ í•­ëª©:**

- ê°œì¸ì •ë³´ íƒœê·¸ ë³€í™˜: `@NAME` â†’ `[NAME]`, `@HOSPITAL` â†’ `[PLACE]`
- ê³¼ë„í•œ ê³µë°± ì œê±°
- íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬

**ì´ìœ :** ì„ë² ë”© í’ˆì§ˆ í–¥ìƒ ë° ê°œì¸ì •ë³´ ë³´í˜¸

---

## ğŸ“ ì¶œë ¥ í˜•ì‹

### docs_for_vectordb.jsonl

```json
{
  "id": "D001_1_chunk_3",
  "content": "ìƒë‹´ì‚¬: ìš”ì¦˜ ì–´ë– ì„¸ìš”?\në‚´ë‹´ì: ë„ˆë¬´ í˜ë“¤ì–´ìš”\nìƒë‹´ì‚¬: êµ¬ì²´ì ìœ¼ë¡œ...",
  "metadata": {
    "source_id": "D001",
    "session_no": 1,
    "category": "DEPRESSION",
    "chunk_idx": 3,
    "counselor_response": "êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì ì´ í˜ë“œì‹ ê°€ìš”?",
    "speaker": "ë‚´ë‹´ì"
  }
}
```

---

## ğŸ› ï¸ ì‹¤í–‰ ë°©ë²•

```bash
python src/data/preprocess_data.py \
    --txt_root data/raw \
    --json_root data/raw \
    --out_dir data/processed \
    --window 1
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- **ì†ŒìŠ¤ ì½”ë“œ**: `src/data/preprocess_data.py`
- **ì €ì**: ì¥ì´ì„ 
- **ìµœì¢… ìˆ˜ì •**: 2026-01-06
