"""
FileName    : reset_and_rebuild.py
Auth        : ë°•ìˆ˜ë¹ˆ
Date        : 2026-01-28
Description : ë°ì´í„° íŒŒì´í”„ë¼ì¸ ë¦¬ì…‹ ë° ì¬ì²˜ë¦¬ í†µí•© ìŠ¤í¬ë¦½íŠ¸
Issue/Note  : ê¸°ì¡´ ë°ì´í„° ì‚­ì œ â†’ ì „ì²˜ë¦¬ â†’ ì„ë² ë”© ìë™í™”
"""

# -------------------------------------------------------------
# Imports
# -------------------------------------------------------------

import os
import sys
import shutil
import argparse
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from config.db_config import DatabaseConfig


# -------------------------------------------------------------
# Configuration
# -------------------------------------------------------------

# ì‚­ì œ ëŒ€ìƒ ê²½ë¡œ
PATHS_TO_DELETE = [
    DatabaseConfig.PROCESSED_DATA_DIR,
    DatabaseConfig.CHROMA_DB_DIR,
    DatabaseConfig.SQLITE_DB_PATH,
]

# ì „ì²˜ë¦¬ ê¸°ë³¸ ê²½ë¡œ
DEFAULT_TXT_ROOT = PROJECT_ROOT / "data" / "raw" / "16.ì‹¬ë¦¬ìƒë‹´ ë°ì´í„°" / "3.ê°œë°©ë°ì´í„°" / "1.ë°ì´í„°" / "Training" / "01.ì›ì²œë°ì´í„°"
DEFAULT_JSON_ROOT = PROJECT_ROOT / "data" / "raw" / "16.ì‹¬ë¦¬ìƒë‹´ ë°ì´í„°" / "3.ê°œë°©ë°ì´í„°" / "1.ë°ì´í„°" / "Training" / "02.ë¼ë²¨ë§ë°ì´í„°"
DEFAULT_OUT_DIR = DatabaseConfig.PROCESSED_DATA_DIR


# -------------------------------------------------------------
# Step 1: Clean existing data
# -------------------------------------------------------------

def clean_existing_data(dry_run: bool = False) -> None:
    """
    ê¸°ì¡´ ì²˜ë¦¬ ë°ì´í„° ì‚­ì œ
    
    Args:
        dry_run: Trueë©´ ì‚­ì œí•˜ì§€ ì•Šê³  ëŒ€ìƒë§Œ ì¶œë ¥
    """
    print("\n" + "=" * 60)
    print("STEP 1: ê¸°ì¡´ ë°ì´í„° ì •ë¦¬")
    print("=" * 60)
    
    for path in PATHS_TO_DELETE:
        path = Path(path)
        if path.exists():
            if dry_run:
                print(f"   [DRY-RUN] ì‚­ì œ ì˜ˆì •: {path}")
            else:
                if path.is_dir():
                    shutil.rmtree(path)
                    print(f"   âœ… ì‚­ì œë¨ (ë””ë ‰í† ë¦¬): {path}")
                else:
                    path.unlink()
                    print(f"   âœ… ì‚­ì œë¨ (íŒŒì¼): {path}")
        else:
            print(f"   â­ï¸  ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {path}")


# -------------------------------------------------------------
# Step 2: Run preprocessing
# -------------------------------------------------------------

def run_preprocessing(txt_root: Path, json_root: Path, out_dir: Path, window: int = 1) -> bool:
    """
    ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (subprocess ì‚¬ìš©)
    
    Args:
        txt_root: ì›ì²œ í…ìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ
        json_root: ë¼ë²¨ë§ JSON ë°ì´í„° ê²½ë¡œ
        out_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        window: ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° í¬ê¸°
    
    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    import subprocess
    
    print("\n" + "=" * 60)
    print("STEP 2: ë°ì´í„° ì „ì²˜ë¦¬")
    print("=" * 60)
    
    try:
        preprocess_script = PROJECT_ROOT / "src" / "data" / "preprocess_data.py"
        cmd = [
            sys.executable,
            str(preprocess_script),
            "--txt_root", str(txt_root),
            "--json_root", str(json_root),
            "--out_dir", str(out_dir),
            "--window", str(window)
        ]
        
        result = subprocess.run(cmd, cwd=str(PROJECT_ROOT), capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"   âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {result.stderr}")
            return False
        
        print(result.stdout)
        print("   âœ… ì „ì²˜ë¦¬ ì™„ë£Œ")
        return True
    except Exception as e:
        print(f"   âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return False



# -------------------------------------------------------------
# Step 3: Run embedding
# -------------------------------------------------------------

def run_embedding(input_path: Path, batch_size: int = 100, limit: int = None) -> bool:
    """
    ë²¡í„°DB ì„ë² ë”© ì‹¤í–‰
    
    Args:
        input_path: ì…ë ¥ JSONL íŒŒì¼ ê²½ë¡œ
        batch_size: ë°°ì¹˜ í¬ê¸°
        limit: í…ŒìŠ¤íŠ¸ìš© ìµœëŒ€ ë¬¸ì„œ ìˆ˜
    
    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    print("\n" + "=" * 60)
    print("STEP 3: ë²¡í„°DB ì„ë² ë”©")
    print("=" * 60)
    
    if not input_path.exists():
        print(f"   âŒ ì…ë ¥ íŒŒì¼ ì—†ìŒ: {input_path}")
        return False
    
    try:
        from src.data.embed_to_vectordb import embed_documents
        stats = embed_documents(
            input_path=input_path,
            batch_size=batch_size,
            limit=limit
        )
        print(f"   âœ… ì„ë² ë”© ì™„ë£Œ: {stats}")
        return True
    except Exception as e:
        print(f"   âŒ ì„ë² ë”© ì‹¤íŒ¨: {e}")
        return False


# -------------------------------------------------------------
# Step 4: Print summary
# -------------------------------------------------------------

def print_summary(out_dir: Path) -> None:
    """
    ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    
    Args:
        out_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    print("\n" + "=" * 60)
    print("STEP 4: ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    summary_path = out_dir / "docs_summary.txt"
    if summary_path.exists():
        print(summary_path.read_text(encoding="utf-8"))
    else:
        print("   âš ï¸  ìš”ì•½ íŒŒì¼ ì—†ìŒ")
    
    # VectorDB ë¬¸ì„œ ìˆ˜ í™•ì¸
    try:
        from src.database import VectorStore
        vs = VectorStore()
        count = vs.get_document_count()
        print(f"\n   ğŸ“Š VectorDB ë¬¸ì„œ ìˆ˜: {count:,}")
    except Exception as e:
        print(f"   âš ï¸  VectorDB ì¡°íšŒ ì‹¤íŒ¨: {e}")


# -------------------------------------------------------------
# Main
# -------------------------------------------------------------

def main(
    txt_root: str = None,
    json_root: str = None,
    out_dir: str = None,
    window: int = 1,
    batch_size: int = 100,
    limit: int = None,
    dry_run: bool = False,
    skip_clean: bool = False,
    skip_preprocess: bool = False,
    skip_embed: bool = False
) -> None:
    """
    ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤í–‰
    """
    txt_root = Path(txt_root) if txt_root else DEFAULT_TXT_ROOT
    json_root = Path(json_root) if json_root else DEFAULT_JSON_ROOT
    out_dir = Path(out_dir) if out_dir else DEFAULT_OUT_DIR
    
    print("\n" + "=" * 60)
    print("ğŸ”„ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ë¦¬ì…‹ ë° ì¬ì²˜ë¦¬")
    print("=" * 60)
    print(f"   TXT ê²½ë¡œ: {txt_root}")
    print(f"   JSON ê²½ë¡œ: {json_root}")
    print(f"   ì¶œë ¥ ê²½ë¡œ: {out_dir}")
    print(f"   ìœˆë„ìš° í¬ê¸°: {window}")
    print(f"   ë°°ì¹˜ í¬ê¸°: {batch_size}")
    if limit:
        print(f"   ì œí•œ: {limit}ê°œ")
    if dry_run:
        print("   âš ï¸  DRY-RUN ëª¨ë“œ")
    
    # Step 1: Clean
    if not skip_clean:
        clean_existing_data(dry_run=dry_run)
    
    if dry_run:
        print("\n   [DRY-RUN] ì‹¤ì œ ì²˜ë¦¬ëŠ” ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ")
        return
    
    # Step 2: Preprocess
    if not skip_preprocess:
        success = run_preprocessing(txt_root, json_root, out_dir, window)
        if not success:
            print("\nâŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨ë¡œ ì¤‘ë‹¨")
            return
    
    # Step 3: Embed
    if not skip_embed:
        input_path = out_dir / "docs_for_vectordb.jsonl"
        success = run_embedding(input_path, batch_size, limit)
        if not success:
            print("\nâŒ ì„ë² ë”© ì‹¤íŒ¨ë¡œ ì¤‘ë‹¨")
            return
    
    # Step 4: Summary
    print_summary(out_dir)
    
    print("\n" + "=" * 60)
    print("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("=" * 60)


# -------------------------------------------------------------
# Entry Point
# -------------------------------------------------------------

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ë°ì´í„° íŒŒì´í”„ë¼ì¸ ë¦¬ì…‹ ë° ì¬ì²˜ë¦¬")
    parser.add_argument("--txt_root", type=str, default=None, help="ì›ì²œ ë°ì´í„° ê²½ë¡œ")
    parser.add_argument("--json_root", type=str, default=None, help="ë¼ë²¨ë§ ë°ì´í„° ê²½ë¡œ")
    parser.add_argument("--out_dir", type=str, default=None, help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--window", type=int, default=1, help="ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° í¬ê¸°")
    parser.add_argument("--batch_size", type=int, default=100, help="ì„ë² ë”© ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--limit", type=int, default=None, help="í…ŒìŠ¤íŠ¸ìš© ìµœëŒ€ ë¬¸ì„œ ìˆ˜")
    parser.add_argument("--dry-run", action="store_true", help="ì‹¤ì œ ì‹¤í–‰ ì—†ì´ í™•ì¸ë§Œ")
    parser.add_argument("--skip-clean", action="store_true", help="ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--skip-preprocess", action="store_true", help="ì „ì²˜ë¦¬ ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--skip-embed", action="store_true", help="ì„ë² ë”© ê±´ë„ˆë›°ê¸°")
    
    args = parser.parse_args()
    
    main(
        txt_root=args.txt_root,
        json_root=args.json_root,
        out_dir=args.out_dir,
        window=args.window,
        batch_size=args.batch_size,
        limit=args.limit,
        dry_run=args.dry_run,
        skip_clean=args.skip_clean,
        skip_preprocess=args.skip_preprocess,
        skip_embed=args.skip_embed
    )
